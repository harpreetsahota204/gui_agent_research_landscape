# Top 20 Papers by Recent Activity (6-Month Focus)

|   Rank | ArXiv                                                                                                  | Title                                                                                                          |   Year |   Citations |   Citations/Year |   Recent (6mo) |   Very Recent (3mo) |   Recent Ratio | Summary                                                                                                                                                 | Contributions                                                                                                                                            |
|--------|--------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|--------|-------------|------------------|----------------|---------------------|----------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|
|      1 | [![arXiv](https://img.shields.io/badge/arXiv-2504.01382-b31b1b.svg)](https://arxiv.org/abs/2504.01382) | An Illusion of Progress? Assessing the Current State of Web Agents                                             |   2025 |           4 |                4 |              3 |                   1 |          0.75  | The paper critically assesses current web agents, identifies benchmark shortcomings, introduces Online-Mind2Web benchmark, develops LLM-as-a-Judge...   | This work differs from related work by introducing a realistic online benchmark (Online-Mind2Web) and an LLM-based automatic evaluation method with...   |
|      2 | [![arXiv](https://img.shields.io/badge/arXiv-2504.07491-b31b1b.svg)](https://arxiv.org/abs/2504.07491) | Kimi-VL Technical Report                                                                                       |   2025 |           3 |                3 |              2 |                   0 |          0.667 | Kimi-VL introduces an efficient MoE-based vision-language model with a 128K context window, native-resolution MoonViT encoder for high-resolution...    | The work advances over prior open-source VLMs by integrating MoE for scalable efficiency, native-resolution vision encoding, and long-context...         |
|      3 | [![arXiv](https://img.shields.io/badge/arXiv-2412.05467-b31b1b.svg)](https://arxiv.org/abs/2412.05467) | The BrowserGym Ecosystem for Web Agent Research                                                                |   2024 |           8 |                8 |              5 |                   1 |          0.625 | The paper introduces the BrowserGym ecosystem, a unified framework for evaluating web agents with standardized benchmarks and AgentLab for agent...     | This work differs from related work by unifying existing benchmarks into a cohesive ecosystem, introducing AgentLab for agent creation/testing, and...   |
|      4 | [![arXiv](https://img.shields.io/badge/arXiv-2409.14337-b31b1b.svg)](https://arxiv.org/abs/2409.14337) | MobileViews: A Large-Scale Mobile GUI Dataset                                                                  |   2024 |           7 |                7 |              4 |                   0 |          0.571 | The paper introduces MobileViews, the largest mobile screen dataset with over 600K screenshot-view hierarchy pairs from 20K+ Android apps. It...        | MobileViews differs from prior work by providing a large-scale, high-fidelity dataset collected over 81,600 device-hours using automated app...          |
|      5 | [![arXiv](https://img.shields.io/badge/arXiv-2410.11871-b31b1b.svg)](https://arxiv.org/abs/2410.11871) | TinyClick: Single-Turn Agent for Empowering GUI Automation                                                     |   2024 |           7 |                7 |              4 |                   1 |          0.571 | TinyClick introduces a single-turn UI agent leveraging the Florence-2-Base model for efficient GUI automation. It achieves high accuracy (73.8% on...   | TinyClick differs from prior work by emphasizing efficiency and cost-effectiveness through multitask training and MLLM augmentation, achieving...        |
|      6 | [![arXiv](https://img.shields.io/badge/arXiv-2410.14803-b31b1b.svg)](https://arxiv.org/abs/2410.14803) | DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agents              |   2024 |          11 |               11 |              6 |                   0 |          0.545 | The paper introduces DistRL, an asynchronous distributed reinforcement learning framework designed to enhance the efficiency of online fine-tuning...   | DistRL differs from prior work by addressing the inefficiencies of synchronous multi-machine setups (e.g., DigiRL) through asynchronous distributed...   |
|      7 | [![arXiv](https://img.shields.io/badge/arXiv-2412.16256-b31b1b.svg)](https://arxiv.org/abs/2412.16256) | Aria-UI: Visual Grounding for GUI Instructions                                                                 |   2024 |          14 |               14 |              7 |                   1 |          0.5   | Aria-UI introduces a pure-vision approach for GUI grounding without relying on HTML or AXTree inputs, proposes a scalable data pipeline for diverse...  | Unlike prior work reliant on auxiliary inputs (HTML/AXTree) or limited instruction data, Aria-UI combines pure vision with dynamic context modeling...   |
|      8 | [![arXiv](https://img.shields.io/badge/arXiv-2411.02337-b31b1b.svg)](https://arxiv.org/abs/2411.02337) | WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning                      |   2024 |           8 |                8 |              4 |                   1 |          0.5   | Introduces WebRL, a self-evolving online curriculum reinforcement learning framework for training open LLMs as web agents. Addresses task scarcity,...  | Proposes WebRL as a dynamic, online learning framework that evolves tasks and rewards based on agent progress, unlike static task sets in prior work.... |
|      9 | [![arXiv](https://img.shields.io/badge/arXiv-2411.06559-b31b1b.svg)](https://arxiv.org/abs/2411.06559) | Is Your LLM Secretly a World Model of the Internet? Model-Based Planning for Web Agents                        |   2024 |           6 |                6 |              3 |                   1 |          0.5   | The paper introduces WebDreamer, a model-based planning framework for web agents that uses LLMs as world models and value functions. It presents a...   | This work differs from related work by integrating LLMs as world models for model-based planning in web agents, addressing the limitations of...         |
|     10 | [![arXiv](https://img.shields.io/badge/arXiv-2502.13130-b31b1b.svg)](https://arxiv.org/abs/2502.13130) | Magma: A Foundation Model for Multimodal AI Agents                                                             |   2025 |           4 |                4 |              2 |                   1 |          0.5   | Magma introduces a foundation model for multimodal AI agents that integrates verbal intelligence (vision-language understanding) with...                | Magma differs from related work by unifying multimodal understanding with spatial-temporal action planning through SoM/ToM pretraining, enabling...      |
|     11 | [![arXiv](https://img.shields.io/badge/arXiv-2410.13232-b31b1b.svg)](https://arxiv.org/abs/2410.13232) | Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation                   |   2024 |           4 |                4 |              2 |                   0 |          0.5   | This paper introduces a world-model-augmented (WMA) web agent that simulates action outcomes to improve decision-making in web navigation. It...        | This work differs from prior research by integrating world models into LLM-based web agents, enabling foresight of environmental dynamics. Unlike...     |
|     12 | [![arXiv](https://img.shields.io/badge/arXiv-2412.13194-b31b1b.svg)](https://arxiv.org/abs/2412.13194) | Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents                 |   2024 |           4 |                4 |              2 |                   0 |          0.5   | The paper introduces Proposer-Agent-Evaluator (PAE), a framework enabling foundation model agents to autonomously discover and refine skills through... | PAE differs from prior work by replacing static human-curated task templates with an autonomous context-aware task proposer, integrating VLM-based...    |
|     13 | [![arXiv](https://img.shields.io/badge/arXiv-2410.08164-b31b1b.svg)](https://arxiv.org/abs/2410.08164) | Agent S: An Open Agentic Framework that Uses Computers Like a Human                                            |   2024 |          11 |               11 |              5 |                   0 |          0.455 | Agent S introduces an open agentic framework for GUI interaction, addressing domain knowledge acquisition, long-horizon planning, and dynamic...        | Agent S integrates existing MLLM capabilities with novel architecture components (ACI, hierarchical planning) to enable zero-shot GUI control,...        |
|     14 | [![arXiv](https://img.shields.io/badge/arXiv-2410.02907-b31b1b.svg)](https://arxiv.org/abs/2410.02907) | NNetNav: Unsupervised Learning of Browser Agents Through Environment Interaction in the Wild                   |   2024 |           9 |                9 |              4 |                   0 |          0.444 | NNetNav introduces an unsupervised method for training browser agents by generating synthetic demonstrations through environment interaction. It...     | Unlike prior work reliant on human demonstrations or supervised fine-tuning, NNetNav generates synthetic data through interaction and uses...            |
|     15 | [![arXiv](https://img.shields.io/badge/arXiv-2410.18963-b31b1b.svg)](https://arxiv.org/abs/2410.18963) | OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning                                      |   2024 |           7 |                7 |              3 |                   0 |          0.429 | OSCAR introduces a generalist agent for OS-level GUI interaction using state-aware reasoning and dynamic re-planning. It translates natural language... | OSCAR differs from prior work by combining state-aware re-planning with code-centric control, enabling real-time OS interaction through standardized...  |
|     16 | [![arXiv](https://img.shields.io/badge/arXiv-2412.18116-b31b1b.svg)](https://arxiv.org/abs/2412.18116) | AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation                                                |   2024 |           7 |                7 |              3 |                   0 |          0.429 | The paper introduces AutoDroid-V2, a system that leverages small language models (SLMs) and code generation for mobile GUI task automation. It...       | AutoDroid-V2 differs from prior work by shifting from cloud-based LLMs to on-device SLMs for code generation, using app-specific API documentation...    |
|     17 | [![arXiv](https://img.shields.io/badge/arXiv-2412.04454-b31b1b.svg)](https://arxiv.org/abs/2412.04454) | Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction                                              |   2024 |          17 |               17 |              7 |                   1 |          0.412 | Aguvis introduces a unified vision-based framework for autonomous GUI agents, addressing challenges in textual representation dependency,...            | Unlike prior work reliant on text or platform-specific actions, Aguvis operates directly on screen images with cross-platform standardization and...     |
|     18 | [![arXiv](https://img.shields.io/badge/arXiv-2410.19609-b31b1b.svg)](https://arxiv.org/abs/2410.19609) | OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization |   2024 |           5 |                5 |              2 |                   0 |          0.4   | The paper introduces an open-source framework for multimodal web agents that enable iterative real-world exploration, feedback, and optimization. It... | This work differs from related work by focusing on real-world, multimodal web agents using open-source models, addressing the lack of ground-truth...    |
|     19 | [![arXiv](https://img.shields.io/badge/arXiv-2410.17883-b31b1b.svg)](https://arxiv.org/abs/2410.17883) | Lightweight Neural App Control                                                                                 |   2024 |           5 |                5 |              2 |                   0 |          0.4   | The paper introduces LiMAC, a lightweight architecture for mobile app control that combines a small Action Transformer (AcT) with a fine-tuned...       | LiMAC differs from related work by integrating a lightweight transformer network with a fine-tuned VLM, enabling efficient mobile app control without... |
|     20 | [![arXiv](https://img.shields.io/badge/arXiv-2504.00906-b31b1b.svg)](https://arxiv.org/abs/2504.00906) | Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents                              |   2025 |           5 |                5 |              2 |                   0 |          0.4   | Agent S2 introduces a compositional generalist-specialist framework for computer use agents, addressing GUI grounding, long-horizon planning, and...    | Unlike prior work relying on single generalist models, Agent S2 introduces a compositional architecture that delegates tasks between generalist and...   |

# üöÄ **Summary of Top 20 Recent Activity Papers' Contributions**

These papers represent the **cutting edge** of GUI agent research - they have the highest recent citation activity (6-month focus), showing what researchers are paying attention to **RIGHT NOW**.

## **üî• Brand New 2025 Papers (Highest Recent Activity)**

### **1. An Illusion of Progress? (2025) - Recent Ratio: 0.75**
**Key Innovation**: Realistic online benchmark (Online-Mind2Web) + LLM-based automatic evaluation
**Impact**: Critical assessment of current web agent capabilities with high human agreement

### **2. Kimi-VL Technical Report (2025) - Recent Ratio: 0.667**
**Key Innovation**: MoE architecture for VLMs + native-resolution vision + long-context reasoning
**Impact**: Scalable efficiency through sparse activation + CoT/RL for multi-step reasoning

### **10. Magma (2025) - Recent Ratio: 0.5**
**Key Innovation**: Unified multimodal understanding with spatial-temporal action planning
**Impact**: Generalizable agentic capabilities across digital and physical domains

### **20. Agent S2 (2025) - Recent Ratio: 0.4**
**Key Innovation**: Compositional generalist-specialist architecture + Mixture-of-Grounding
**Impact**: Overcomes single-model limitations through task delegation

## **üõ†Ô∏è Infrastructure & Ecosystem Papers (Late 2024)**

### **3. BrowserGym Ecosystem (2024) - Recent Ratio: 0.625**
**Key Innovation**: Unified benchmark ecosystem + AgentLab for agent creation/testing
**Impact**: First large-scale multi-benchmark evaluation of LLMs

### **4. MobileViews Dataset (2024) - Recent Ratio: 0.571**
**Key Innovation**: Large-scale dataset from 81,600 device-hours of automated app traversal
**Impact**: Addresses Rico limitations through greater diversity and scale

### **7. Aria-UI (2024) - Recent Ratio: 0.5**
**Key Innovation**: Pure vision + dynamic context modeling via action histories
**Impact**: GUI instruction grounding without structural annotations

## **üß† Advanced Learning & Planning**

### **8. WebRL (2024) - Recent Ratio: 0.5**
**Key Innovation**: Self-evolving online curriculum RL for web agents
**Impact**: Dynamic task evolution based on agent progress without expert demonstrations

### **9. World Model Planning (2024) - Recent Ratio: 0.5**
**Key Innovation**: LLMs as world models for model-based planning (WebDreamer + Dreamer-7B)
**Impact**: Efficient planning without sandbox environments

### **11. Web Agents with World Models (2024) - Recent Ratio: 0.5**
**Key Innovation**: Transition-focused observation abstraction for world model training
**Impact**: Foresight of environmental dynamics + outperforms tree-search agents

### **12. PAE Framework (2024) - Recent Ratio: 0.5**
**Key Innovation**: Autonomous skill discovery with context-aware task proposer + VLM evaluation
**Impact**: End-to-end skill discovery without manual instruction specification

## **‚ö° Efficiency & Optimization**

### **5. TinyClick (2024) - Recent Ratio: 0.571**
**Key Innovation**: Lightweight model achieving competitive performance through multitask training
**Impact**: Cost-effective alternative to large agentic models

### **6. DistRL (2024) - Recent Ratio: 0.545**
**Key Innovation**: Asynchronous distributed RL for on-device control agents
**Impact**: Addresses synchronous multi-machine setup inefficiencies

### **16. AutoDroid-V2 (2024) - Recent Ratio: 0.429**
**Key Innovation**: On-device SLMs for code generation + app-specific API documentation
**Impact**: Privacy-preserving mobile automation without cloud dependency

### **19. LiMAC (2024) - Recent Ratio: 0.4**
**Key Innovation**: Lightweight transformer (‚âà500M params) + gated architecture
**Impact**: Efficient mobile control without large foundation models

## **üéØ Specialized Approaches**

### **13. Agent S (2024) - Recent Ratio: 0.455**
**Key Innovation**: Zero-shot GUI control with hierarchical planning + cross-platform adaptability
**Impact**: Experience-driven task planning integration

### **14. NNetNav (2024) - Recent Ratio: 0.444**
**Key Innovation**: Unsupervised learning through environment interaction + language-based pruning
**Impact**: Synthetic data generation without human demonstrations

### **15. OSCAR (2024) - Recent Ratio: 0.429**
**Key Innovation**: State-aware re-planning + code-centric OS control
**Impact**: Real-time OS interaction in executable environments

### **17. Aguvis (2024) - Recent Ratio: 0.412**
**Key Innovation**: Pure vision agents with cross-platform standardization + structured reasoning
**Impact**: Fully autonomous vision-based GUI interaction without closed-source models

### **18. OpenWebVoyager (2024) - Recent Ratio: 0.4**
**Key Innovation**: Iterative exploration-feedback-optimization cycle using open-source models
**Impact**: Real-world multimodal agents without closed-source dependency

## **üìä Key Insights from Recent Activity Papers**

### **üîÑ Major Trends**
1. **Open Source Movement**: Move away from closed-source models (OpenWebVoyager, Aguvis, LiMAC)
2. **Efficiency Focus**: Lightweight models competing with large ones (TinyClick, LiMAC, AutoDroid-V2)
3. **Advanced Planning**: World models and curriculum learning (WebRL, WebDreamer, PAE)
4. **Ecosystem Building**: Unified benchmarks and frameworks (BrowserGym, MobileViews)
5. **Real-World Focus**: Moving from simulated to actual environments (OSCAR, DistRL)

### **üéØ What's Hot Right Now**
- **Critical Assessment**: Papers questioning current progress (An Illusion of Progress)
- **Multimodal Foundation Models**: Advanced VLMs with reasoning (Kimi-VL, Magma)
- **Compositional Architectures**: Specialist-generalist frameworks (Agent S2)
- **Autonomous Learning**: Self-improving systems (WebRL, PAE, NNetNav)
- **Cross-Platform Solutions**: Unified approaches across devices (Aguvis, Agent S, OSCAR)

The recent activity papers show a field **maturing rapidly** with focus on **practical deployment**, **efficiency**, **open-source alternatives**, and **autonomous improvement** - moving beyond proof-of-concepts to production-ready systems.


*Generated on: 2025-08-15 01:44:43*
*Total entries: 20*
